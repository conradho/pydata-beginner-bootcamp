{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Background and Setup\n",
    "\n",
    "So let's say you are a systematic trader and you want to build out your infrastructure to do research and backtesting. What should you look at? Today we are going to look at a couple finance libraries that may be useful for you.\n",
    "\n",
    "Because of the level of interest, the quant finance area has some really awesome libraries. However, there are also some less well-supported libraries out there.\n",
    "\n",
    "Today, while setting up a backtester, we will be channelling our inner hacker skills and go outside of our comfort zones to poke around unfamiliar libraries with confusing documentation.\n",
    "\n",
    "Hopefully, by the end of this tutorial, you will also learn some new skills that you can use when you next encounter a befuddling library that you need to use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# some setup stuff:\n",
    "# make sure you have the most updated libraries\n",
    "# pip3.6 install --user --upgrade gevent pandas quandl\n",
    "\n",
    "# get notebook to show graphs\n",
    "%pylab inline\n",
    "matplotlib.style.use('ggplot')\n",
    "# zipline spams a lot of warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first library that we will look at is Quandl. Quandl is one of those really awesome libraries. They are a data aggregator that gives you a unified api to directly get data. And they return that data in pandas dataframes. Super simple, and super nice.\n",
    "\n",
    "From Quandl, you can access data from yahoo finance, to the St Louis Fred, to the commitment of traders report etc. They have a free api as well as a paid api (eg: [vendors](https://www.quandl.com/vendors) who sell their data on their platform).\n",
    "\n",
    "Having a unified api means that you don't need to waste time getting your code to interface with 10 different data vendors, or to write different scrapers just to get your data. The flip side is they now control your data flow and if you need to access their api over 50k times a day, you may end up having to be paying for the api access.\n",
    "\n",
    "If you do collect a lot of niche/proprietary data, the best tool for you may be [scrapy](http://scrapy.org/). They provide a very well structured way for you to write your scrapers, meaning that you won't just be stuck with a potpourri of different scrapers- instead you will once again plug into a unified pipeline as soon as possible.\n",
    "\n",
    "There are even specialized Scraping-as-a-Service companies such as [scrapy cloud](http://scrapinghub.com) that you could consider using. Otherwise, you can also just run it as a cron job/scheduled task.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import quandl\n",
    "quandl.ApiConfig.api_key = \"nCnqK9fotdzGHTfUUsz1\"\n",
    "\n",
    "# first, go to quandl.com and search for whatever ticker symbol tickles your fancy\n",
    "# let's say we want to look at (continuous) front month crude vs e-mini S&Ps\n",
    "cl = quandl.get('CHRIS/CME_CL1')\n",
    "es = quandl.get('CHRIS/CME_ES1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Quandl.get() returns a pandas dataframe, so you can use all the pandas goodies\n",
    "# For example, you can use tail to look at the most recent data, just like the unix tail binary!\n",
    "cl.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# you can also get statistics\n",
    "es.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, let's take a look at zipline. We are going to try to get it to use Quandl data for the backtest. Zipline is a backtesting library that Quantopian opened sourced, but also develops and use for themselves.\n",
    "\n",
    "Quantopian, by the way, offers a really cool platform for you to develop quant algorithms, with backtesters, and risk analytics etc, and I've heard nothing but good things about them. The main problems that I have with it is that the tradeable universe is currently US equities only (useless for a macro guy), and you don't really have the flexibility to add whatever you want and mold it to fit your needs.\n",
    "\n",
    "On the other hand, I may be way too extreme when it comes to flexibility. I am all about customizing my text editor (yay vim!), and the git project I've contributed to most is probably my vimrc/bashrc etc dotfiles config repo. I also need to customize my email client so much that I'm use mutt. So _you_ may not actually find the inflexibility as suffocating as I do. If that is the case, Quantopian might actually be your best option when you are starting out- everything works out of the box etc.\n",
    "\n",
    "The problem, however, is that documentation for zipline itself is a bit sparse. Try to follow the [example](http://www.zipline.io/beginner-tutorial.html#my-first-algorithm) from the documentation yourself, and try to get it to work with the Quandl dataset that we just downloaded.\n",
    "\n",
    "Some problems that I encountered were:\n",
    "- where do you get these functions? (ie. where do you imported them from?)\n",
    "- where is buyapple.py?\n",
    "- once I substituted in the Quandl dataset, there was a error with comparing timezone-naive and timezone-aware dates\n",
    "- how does zipline know which price is which from the data? Do I need to label the data somehow?\n",
    "- there are no more errors, but why are the trades not getting filled?\n",
    "\n",
    "Some tips:\n",
    "- search for the functions within the zipline github repo to find where you can import them\n",
    "- test out your guesses- figure out how to isolate your guesses, by separating out the relevant code into it's own notebook cell block, using print statements, and raising exceptions\n",
    "- read important files within the github repo source code to try to understand it more\n",
    "- search on stack overflow for the relavant stack trace/error\n",
    "- search for code snippets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import zipline as zp\n",
    "from zipline.api import order, symbol\n",
    "\n",
    "class BuyCrude(zp.TradingAlgorithm):\n",
    "    def handle_data(self, data):\n",
    "        order(symbol('cl'), 10)\n",
    "\n",
    "algo = BuyCrude()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fortunately, we are coding in python..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# this means that we can peek into the object internals\n",
    "algo.__dict__.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# let's look at one of them\n",
    "algo.slippage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# zipline looks for a column called 'volume'. if there is no volume your trade will not get filled\n",
    "data = pd.concat({'es': es.Last, 'cl': cl.Last, 'volume': cl.Volume}, axis=1)\n",
    "\n",
    "# zipline requires timezone aware timestamps\n",
    "data_with_tz = data.tz_localize('UTC')\n",
    "\n",
    "data_with_tz.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Oh hey s&p futures don't go back that far... Let's cut off all the data that is irrelevant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "earliest_es_date = es.index[0]\n",
    "# at first glance, you could just do\n",
    "data_with_tz[earliest_es_date:].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# but just in case there is no matching precise date, we can also take the closest date instead\n",
    "closest_date = data.index.searchsorted(earliest_es_date)\n",
    "data_with_tz.iloc[closest_date:].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# For the purposes of this tutorial, let's only take one yr of data so this will run faster for now\n",
    "\n",
    "from datetime import datetime, timedelta\n",
    "import pytz\n",
    "\n",
    "one_year_ago = datetime.now(tz=pytz.utc) - timedelta(days=365)\n",
    "limited_data = data_with_tz[data_with_tz.index > one_year_ago]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "report = algo.run(limited_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# the result that we get back is a pandas dataframe\n",
    "report.iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "report.portfolio_value.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# we can see that we are buying every single day\n",
    "report.transactions.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# let's make sure we can access both variables\n",
    "# and let's play with day of the week effects\n",
    "\n",
    "class PairTradeAlgo(zp.TradingAlgorithm):\n",
    "    def handle_data(self, data):\n",
    "        if data['cl'].dt.dayofweek == 3:\n",
    "            order(symbol('cl'), 10)\n",
    "            order(symbol('es'), -1)\n",
    "\n",
    "report = PairTradeAlgo().run(limited_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# cool, we double check that we buy only every week now\n",
    "report.transactions.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# let's show the portfolio value chart with the chart of crude and s&p at the same time\n",
    "fig = plt.figure()\n",
    "\n",
    "fig.add_subplot(311)\n",
    "report.portfolio_value.plot()\n",
    "\n",
    "fig.add_subplot(312)\n",
    "limited_data.cl.plot()\n",
    "\n",
    "fig.add_subplot(313)\n",
    "limited_data.es.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "hmm we want to make a pretty chart that also shows our buys/sells entry/exit points. We could parse this from report.transactions, but _there must be a better way_!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class WeeklyAlgo(zp.TradingAlgorithm):\n",
    "    def handle_data(self, data):\n",
    "        buy = False\n",
    "        timestamp = data['cl'].dt\n",
    "        if (timestamp.dayofweek * timestamp.month) % 17 == 3:\n",
    "            order(symbol('cl'), 10)\n",
    "            buy = True\n",
    "        # this puts a buy column and a cl column into the report dataframe we get back\n",
    "        self.record(buy=buy, cl=data['cl']['price'])\n",
    "\n",
    "report = WeeklyAlgo().run(limited_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# magically, those columns appear in our report!\n",
    "report[['buy', 'cl']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# notice that the report time index vs the time stamp is different..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "buy_dates = report[report.buy].index\n",
    "buy_dates[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "crude_price_on_buy_dates = report[report.buy].cl\n",
    "crude_price_on_buy_dates.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, let's make a pretty graph!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fig, (ax1, ax2) = plt.subplots(nrows=2, ncols=1, sharex=True)\n",
    "\n",
    "report.portfolio_value.plot(ax=ax1, title='Portfolio Value')\n",
    "report.cl.plot(ax=ax2, title='Crude Price and Entry Points')\n",
    "crude_price_on_buy_dates.plot(ax=ax2, style='^')\n",
    "\n",
    "\n",
    "##### and below is just formatting/prettifying ######\n",
    "#  If you are confused about the code below, be sure to check out\n",
    "# the data visualization notebook for an explanation\n",
    "\n",
    "fig.suptitle('Backtesting Results')\n",
    "# make space for the title\n",
    "fig.subplots_adjust(top=0.85)\n",
    "\n",
    "# let's give a breakeven level\n",
    "ax1.axhline(100000, color='black')\n",
    "\n",
    "# how many major ticks there are\n",
    "ax1.yaxis.set_major_locator(MaxNLocator(5))\n",
    "ax2.yaxis.set_major_locator(MaxNLocator(5))\n",
    "\n",
    "ax1.tick_params(\n",
    "    which='both',  # both major and minor ticks\n",
    "    bottom='off', top='off', right='off',\n",
    "    labelbottom='off'  # labels along the bottom edge are off\n",
    ")\n",
    "ax2.tick_params(which='both', top='off', right='off')\n",
    "ax2.tick_params(which='minor', bottom='off')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below is an example of how I would have gone about trying to write the Weekly Algo, when I needed to figure out what was in the data variable, but was unable to isolate it easily."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from pprint import pprint\n",
    "class ExplorationAlgo(zp.TradingAlgorithm):\n",
    "    def handle_data(self, data):\n",
    "        pprint(data.__dict__)\n",
    "        pprint(data['cl'].dt.month)\n",
    "        raise\n",
    "report = ExplorationAlgo().run(limited_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you have gotten to this stage, try writing and backtesting a more serious trading strategy!\n",
    "\n",
    "You could also look at another way to solve this problem: adding a [new data source](https://github.com/quantopian/zipline/wiki/How-To-code-a-data-source) to zipline.\n",
    "\n",
    "Check out the moving average and self.add_transform stuff in [this](http://nbviewer.jupyter.org/github/twiecki/financial-analysis-python-tutorial/blob/master/3.%20Backtesting%20using%20Zipline.ipynb) notebook.\n",
    "\n",
    "[fecon235](https://github.com/rsvp/fecon235) seems like a pretty cool library with lots of different ideas you would look at. Try your hand at understand what they do, implement some strategies from there, and then back testing it with zipline!\n",
    "\n",
    "If you enjoy learning through videos, here's a video series by [Sentdex](https://www.youtube.com/playlist?list=PLQVvvaa0QuDeN06s5ervxTfTcVvt-xpZN).\n",
    "\n",
    "And [here](https://www.quantstart.com/articles/Free-Quantitative-Finance-Resources)'s some free data sources to play with."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6",
   "language": "python",
   "name": "python3.6"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
